{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Stock Price Prediction Colab Notebook\n",
        "# This notebook is designed to be run in Google Colab.\n",
        "# Remember to upload all 10 historical CSV files before running.\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 1. SETUP AND FILE MERGE (Updated to be Multi-Feature Ready)\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "# 1.1 Install Necessary Libraries\n",
        "import sys\n",
        "# Install necessary libraries for the project\n",
        "!{sys.executable} -m pip install pandas numpy tensorflow scikit-learn streamlit joblib matplotlib\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from joblib import dump\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f\"TensorFlow Version: {tf.__version__}\")\n",
        "print(\"Starting data merge and cleaning process...\")\n",
        "\n",
        "# Define the list of files and extract the organization name\n",
        "file_names = [\n",
        "    \"AIICO Historical Data.csv\", \"DANGCEM Historical Data.csv\", \"GUINNES Historical Data.csv\",\n",
        "    \"JBERGER Historical Data.csv\", \"NB Historical Data.csv\", \"NESTLE Historical Data.csv\",\n",
        "    \"NSE All Share Historical Data (1).csv\", \"UBA Historical Data.csv\", \"UNILEVE Historical Data.csv\",\n",
        "    \"ZENITHB Historical Data.csv\"\n",
        "]\n",
        "all_data = []\n",
        "\n",
        "# Merge all files first\n",
        "for file_name in file_names:\n",
        "    organisation_name = file_name.split(' ')[0].replace('.csv', '')\n",
        "    try:\n",
        "        df = pd.read_csv(file_name, low_memory=False)\n",
        "        df['Organisation'] = organisation_name\n",
        "        all_data.append(df)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"[ERROR] File not found: {file_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Error processing {file_name}: {e}\")\n",
        "\n",
        "if not all_data:\n",
        "    print(\"\\nNo data was successfully loaded. Aborting process.\")\n",
        "    sys.exit()\n",
        "\n",
        "df_merged = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "# 1.2 Data Cleaning Function (for all non-Date/Organisation columns)\n",
        "def clean_financial_data(df):\n",
        "    # Columns to clean and convert to numeric (Price, Open, High, Low, Vol., Change %)\n",
        "    numeric_cols = ['Price', 'Open', 'High', 'Low']\n",
        "\n",
        "    # 1. Clean common financial formatting issues (commas)\n",
        "    for col in numeric_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].astype(str).str.replace(',', '', regex=False)\n",
        "\n",
        "    # 2. Clean 'Vol.' column (M=Million, K=Thousand)\n",
        "    if 'Vol.' in df.columns:\n",
        "        df['Vol.'] = df['Vol.'].astype(str).str.upper().str.strip()\n",
        "        df['Vol.'] = df['Vol.'].replace(['-'], np.nan)\n",
        "        df['Vol.'] = df['Vol.'].str.replace('M', 'E6', regex=False)\n",
        "        df['Vol.'] = df['Vol.'].str.replace('K', 'E3', regex=False)\n",
        "        df['Vol.'] = pd.to_numeric(df['Vol.'], errors='coerce')\n",
        "        df['Vol.'] = df['Vol.'].fillna(df['Vol.'].mean())\n",
        "\n",
        "    # 3. Clean 'Change %' column (remove '%')\n",
        "    if 'Change %' in df.columns:\n",
        "        df['Change %'] = df['Change %'].astype(str).str.replace('%', '', regex=False)\n",
        "        df['Change %'] = pd.to_numeric(df['Change %'], errors='coerce') / 100 # Convert to decimal change\n",
        "        df['Change %'] = df['Change %'].fillna(0.0)\n",
        "\n",
        "    # 4. Convert all numeric columns\n",
        "    for col in numeric_cols:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "        df[col] = df[col].fillna(df[col].mean()) # Simple imputation for prices\n",
        "\n",
        "    # 5. Convert Date\n",
        "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
        "    df = df.dropna(subset=['Date'])\n",
        "\n",
        "    # Select final features: NOTE: Dropping Unnamed columns\n",
        "    df = df[['Date', 'Organisation', 'Price', 'Open', 'High', 'Low', 'Vol.', 'Change %']].copy()\n",
        "\n",
        "    return df\n",
        "\n",
        "df_cleaned = clean_financial_data(df_merged)\n",
        "\n",
        "# Save the final cleaned master file\n",
        "CLEANED_DATA_FILE = 'cleaned_nigerian_stock_data.csv'\n",
        "df_cleaned.to_csv(CLEANED_DATA_FILE, index=False)\n",
        "\n",
        "print(f\"\\nCleaning complete! The master file '{CLEANED_DATA_FILE}' has been created.\")\n",
        "print(f\"Total rows after cleaning: {len(df_cleaned)}\")\n",
        "print(\"\\nFirst 5 rows of cleaned data:\")\n",
        "print(df_cleaned.head())\n",
        "print(\"\\nData Types after Cleaning:\")\n",
        "print(df_cleaned.dtypes)\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 2. DATA PREPARATION FOR LSTM (Multi-Feature Input)\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "# We will train the model only on the NSE All Share Index data (NSE)\n",
        "# as this represents the overall market movement.\n",
        "df_nse = df_cleaned[df_cleaned['Organisation'] == 'NSE'].sort_values('Date').copy()\n",
        "\n",
        "# List of features to use for training (must match order in app.py)\n",
        "TRAINING_FEATURES = ['Price', 'Open', 'High', 'Low', 'Change %']\n",
        "\n",
        "# Drop the 'Vol.' column for now to simplify multi-feature input,\n",
        "# as Volume requires more complex recursive handling.\n",
        "data_train = df_nse[TRAINING_FEATURES].values\n",
        "\n",
        "# 2.1 Scaling the Data (CRUCIAL)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data_train)\n",
        "\n",
        "# Save the scaler for use in the Streamlit app\n",
        "SCALER_FILE = 'scaler_nse.joblib'\n",
        "dump(scaler, SCALER_FILE)\n",
        "print(f\"\\nMinMaxScaler saved to: {SCALER_FILE}\")\n",
        "\n",
        "# 2.2 Create Input Sequences (X) and Target (y)\n",
        "LOOKBACK_PERIOD = 60 # Use last 60 days to predict the next day\n",
        "\n",
        "X_train = []\n",
        "y_train = [] # Target remains the 'Price' (0th column)\n",
        "\n",
        "for i in range(LOOKBACK_PERIOD, len(scaled_data)):\n",
        "    # X_train: Past 60 rows (5 features)\n",
        "    X_train.append(scaled_data[i-LOOKBACK_PERIOD:i])\n",
        "\n",
        "    # y_train: The price of the current day (the next day after X_train sequence)\n",
        "    # We predict the Price feature, which is the 0th index in TRAINING_FEATURES\n",
        "    y_train.append(scaled_data[i, TRAINING_FEATURES.index('Price')])\n",
        "\n",
        "# Convert to NumPy arrays and ensure correct shape for LSTM\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "\n",
        "print(f\"\\nFinal Training Data Shape (X_train): {X_train.shape}\")\n",
        "print(f\"Final Target Data Shape (y_train): {y_train.shape}\")\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 3. LSTM MODEL DEVELOPMENT\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "# 3.1 Model Definition\n",
        "def create_lstm_model(input_shape):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        # LSTM Layer 1 (returns sequences for the next LSTM layer)\n",
        "        tf.keras.layers.LSTM(100, return_sequences=True, input_shape=input_shape),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "        # LSTM Layer 2 (returns only the final output for the Dense layer)\n",
        "        tf.keras.layers.LSTM(100, return_sequences=False),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "        # Dense layers for final processing\n",
        "        tf.keras.layers.Dense(50),\n",
        "\n",
        "        # Output layer (predicts a single value: the scaled price)\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "model = create_lstm_model(input_shape=(LOOKBACK_PERIOD, len(TRAINING_FEATURES)))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 3.2 Build and Train the LSTM Model (Now using 5 features)\n",
        "print(\"\\nStarting Model Training...\")\n",
        "\n",
        "# Use a validation split to monitor for overfitting\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=25,\n",
        "    batch_size=64,\n",
        "    validation_split=0.1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 3.3 Save the Model\n",
        "MODEL_FILE = 'lstm_model_nse.h5'\n",
        "model.save(MODEL_FILE)\n",
        "print(f\"\\nTraining complete. Trained LSTM model saved to: {MODEL_FILE}\")\n",
        "\n",
        "# --- Plotting Loss for Diagnostics ---\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss During Training')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss (MSE)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n--- Model Training Complete. ---\")\n",
        "print(\"DOWNLOAD THE FOLLOWING FILES FOR STREAMLIT DEPLOYMENT:\")\n",
        "print(f\"1. {CLEANED_DATA_FILE}\")\n",
        "print(f\"2. {SCALER_FILE}\")\n",
        "print(f\"3. {MODEL_FILE}\")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 4. STREAMLIT DEPLOYMENT SCRIPT (Final app.py content)\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "# The content below should be saved as a separate file named 'app.py'\n",
        "# and placed in the same local folder as the three files downloaded above.\n",
        "\n",
        "# NOTE: The Streamlit script relies on the new 5-feature logic.\n",
        "\n",
        "print(\"\\n-----------------------------------------------------------\")\n",
        "print(\"STREAMLIT DEPLOYMENT SCRIPT (app.py)\")\n",
        "print(\"-----------------------------------------------------------\")\n",
        "# Outputting the Streamlit script for the user to copy/save locally."
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.51.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.28.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "TensorFlow Version: 2.19.0\n",
            "Starting data merge and cleaning process...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3120746146.py:85: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
            "  df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cleaning complete! The master file 'cleaned_nigerian_stock_data.csv' has been created.\n",
            "Total rows after cleaning: 23600\n",
            "\n",
            "First 5 rows of cleaned data:\n",
            "        Date Organisation  Price  Open  High   Low        Vol.  Change %\n",
            "0 2024-07-17        AIICO   1.10  1.09  1.10  1.08   9110000.0    0.0092\n",
            "1 2024-07-16        AIICO   1.09  1.15  1.15  1.08  15880000.0    0.0093\n",
            "2 2024-07-15        AIICO   1.08  1.08  1.12  1.08  18910000.0    0.0000\n",
            "3 2024-07-12        AIICO   1.08  1.12  1.10  1.07  14610000.0   -0.0357\n",
            "4 2024-07-11        AIICO   1.12  1.10  1.12  1.09  15630000.0    0.0182\n",
            "\n",
            "Data Types after Cleaning:\n",
            "Date            datetime64[ns]\n",
            "Organisation            object\n",
            "Price                  float64\n",
            "Open                   float64\n",
            "High                   float64\n",
            "Low                    float64\n",
            "Vol.                   float64\n",
            "Change %               float64\n",
            "dtype: object\n",
            "\n",
            "MinMaxScaler saved to: scaler_nse.joblib\n",
            "\n",
            "Final Training Data Shape (X_train): (2300, 60, 5)\n",
            "Final Target Data Shape (y_train): (2300,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m42,400\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m80,400\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m5,050\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">42,400</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,050</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m127,901\u001b[0m (499.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">127,901</span> (499.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m127,901\u001b[0m (499.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">127,901</span> (499.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Model Training...\n",
            "Epoch 1/25\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 190ms/step - loss: 0.0082 - val_loss: 0.0088\n",
            "Epoch 2/25\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 190ms/step - loss: 6.9874e-04 - val_loss: 0.0054\n",
            "Epoch 3/25\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - loss: 5.2638e-04 - val_loss: 0.0032\n",
            "Epoch 4/25\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 211ms/step - loss: 4.4744e-04 - val_loss: 0.0018\n",
            "Epoch 5/25\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 165ms/step - loss: 4.2535e-04 - val_loss: 0.0012\n",
            "Epoch 6/25\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 205ms/step - loss: 4.4549e-04 - val_loss: 0.0011\n",
            "Epoch 7/25\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 164ms/step - loss: 3.1557e-04 - val_loss: 9.4892e-04\n",
            "Epoch 8/25\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 207ms/step - loss: 3.1330e-04 - val_loss: 0.0018\n",
            "Epoch 9/25\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 166ms/step - loss: 2.9780e-04 - val_loss: 0.0012\n",
            "Epoch 10/25\n",
            "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 2.4077e-04"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E0sokMSljIqg",
        "outputId": "5f9b121e-4a3e-468c-fc75-4f3544fa3b5a"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}